{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1.Define the Bayesian interpretation of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> In the Bayesian interpretation, probability measures a degree of belief. Bayes's theorem then links the degree of belief in a proposition before and after accounting for evidence. For example, suppose it is believed with 50% certainty that a coin is twice as likely to land heads than tails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.Define probability of a union of two events with equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> P(A or B) = P(A) + P(B). The chance of any one or of two or more events occurring is called the union of the events. The probability of the union of disjoint events is the sum of their individual probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.What is joint probability? What is its formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->  A joint probability is a possibility of occurring one or more independent events simultaneously, denoted as P (A∩B) or P (A and B). One can calculate it by multiplying the probability of both outcomes = P (A)*P (B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4.What is chain rule of probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> In probability theory, the chain rule permits the calculation of any member of the joint distribution of a set of random variables using only conditional probabilities.\n",
    "\n",
    "The probability that A and B have both occurred is the conditional probability of A given B multiplied by the probability that B has occurred. Hence: Pr(A|B)=Pr(A∩B)Pr(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5.What is conditional probability means? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Conditional probability is known as the possibility of an event or outcome happening, based on the existence of a previous event or outcome. It is calculated by multiplying the probability of the preceding event by the renewed probability of the succeeding, or conditional, event.\n",
    "\n",
    "If A and B are two events in a sample space S, then the conditional probability of A given B is defined as P(A|B)=P(A∩B)P(B), when P(B)>0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6.What are continuous random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> A random variable X is continuous if possible values comprise either a single interval on the number line or a union of disjoint intervals. Example: If in the study of the ecology of a lake, X, the r.v. may be depth measurements at randomly chosen locations.\n",
    "A continuous random variable is a random variable that has only continuous values. Continuous values are uncountable and are related to real numbers. Examples of continuous random variables. The time it takes to complete an exam for a 60 minute test Possible values = all real numbers on the interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7.What are Bernoulli distributions? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Bernoulli distribution is a discrete probability distribution where the Bernoulli random variable can have only 0 or 1 as the outcome. p is the probability of success and 1 - p is the probability of failure. The mean of a Bernoulli distribution is E[X] = p and the variance, Var[X] = p(1-p).\n",
    "\n",
    "A closed form of the probability density function of Bernoulli distribution is P ( x ) = p x ( 1 − p ) 1 − x P(x) = p^{x}(1-p)^{1-x} P(x)=px(1−p)1−x. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8.What is binomial distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> A binomial random variable is the number of successes x in n repeated trials of a binomial experiment. The probability distribution of a binomial random variable is called a binomial distribution (It is also known as a Bernoulli distribution).\n",
    "Formula is P(X= x) = nCxpxqn-x\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.What is Poisson distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> In Poisson distribution, the mean of the distribution is represented by λ and e is constant, which is approximately equal to 2.71828. Then, the Poisson probability is: P(x, λ ) =(e– λ λx)/x! In Poisson distribution, the mean is represented as E(X) = λ.\n",
    "\n",
    "Poisson distribution is a uni-parametric probability tool used to figure out the chances of success, i.e., determining the number of times an event occurs within a specified time frame. The formula for Poisson distribution is P(x;μ)=(e^(-μ) μ^x)/x!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10.Define covariance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Covariance is a measure of the relationship between two random variables and to what extent, they change together. Or we can say, in other words, it defines the changes between the two variables, such that change in one variable is equal to change in another variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q11.Define correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> Correlation is a statistical calculation that indicates that two variables are parallelly related (which means that the variables change together at a constant rate). It is a simple and popularly used tool for defining relationships without delivering a statement concerning the cause and effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12.Define sampling with replacement. Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans--> When a sampling unit is drawn from a finite population and is returned to that population, after its characteristic(s) have been recorded, before the next unit is drawn, the sampling is said to be “with replacement”. In the contrary case the sampling is “without replacement”.\n",
    "\n",
    "When a sampling unit is drawn from a finite population and is returned to that population, after its characteristic(s) have been recorded, before the next unit is drawn, the sampling is said to be “with replacement”. In the contrary case the sampling is “without replacement”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q13.What is sampling without replacement? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->In sampling without replacement, each sample unit of the population has only one chance to be selected in the sample. For example, if one draws a simple random sample such that no unit occurs more than one time in the sample, the sample is drawn without replacement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q14.What is hypothesis? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans-->\n",
    "In Statistics, a hypothesis is defined as a formal statement, which gives the explanation about the relationship between the two or more variables of the specified population. It helps the researcher to translate the given problem to a clear explanation for the outcome of the study.\n",
    "A simple hypothesis might predict a causal relationship between two variables, meaning that one has an effect on the other. Here's an example: More hours spent studying for an exam result in higher grades. Hours spent studying, in this statement, is the independent variable and grades is the dependent variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
